<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Chaithya G. R.  | publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Chaithya</span> G. R.  
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/interests/">
                interests
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">Journal</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ramzi" class="col-sm-8">
    
      <div class="title">NC-PDNet: a Density-Compensated Unrolled Network for 2D and 3D non-Cartesian MRI Reconstruction</div>
      <div class="author">
        
          
            
              
                
                  Ramzi Zaccharie,
                
              
            
          
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  Starck Jean-Luc,
                
              
            
          
        
          
            
              
                
                  and Ciuciu Philippe
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://hal.inria.fr/hal-03188997v3/document" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep Learning has become a very promising avenue for magnetic resonance image (MRI) reconstruction. In this work, we explore the potential of unrolled networks for non-Cartesian acquisition settings. We design the NC-PDNet (Non-Cartesian Primal Dual Netwok), the first density-compensated (DCp) unrolled neural network, and validate the need for its key components via an ablation study. Moreover, we conduct some generalizability experiments to test this network in out-of-distribution settings, for example training on knee data and validating on brain data. The results show that NC-PDNet outperforms baseline (U-Net, Deep image prior) models both visually and quantitatively in all settings. In particular, in the 2D multi-coil acquisition scenario, the NC-PDNet provides up to a 1.2dB improvement in peak signal-to-noise ratio (PSNR) over baseline networks, while also allowing a gain of at least 1dB in PSNR in generalization settings. We provide the open-source implementation of NC-PDNet, and in particular the Non-uniform Fourier Transform in TensorFlow, tested on 2D multi-coil and 3D single-coil k-space data.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="jimaging7030058" class="col-sm-8">
    
      <div class="title">Calibration-Less Multi-Coil Compressed Sensing Magnetic Resonance Image Reconstruction Based on OSCAR Regularization</div>
      <div class="author">
        
          
            
              
                
                  El Gueddari Loubna,
                
              
            
          
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  Chouzenoux Emilie,
                
              
            
          
        
          
            
              
                
                  and Ciuciu Philippe
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://www.mdpi.com/2313-433X/7/3/58/pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Over the last decade, the combination of compressed sensing (CS) with acquisition over multiple receiver coils in magnetic resonance imaging (MRI) has allowed the emergence of faster scans while maintaining a good signal-to-noise ratio (SNR). Self-calibrating techniques, such as ESPiRIT, have become the standard approach to estimating the coil sensitivity maps prior to the reconstruction stage. In this work, we proceed differently and introduce a new calibration-less multi-coil CS reconstruction method. Calibration-less techniques no longer require the prior extraction of sensitivity maps to perform multi-coil image reconstruction but usually alternate estimation sensitivity map estimation and image reconstruction. Here, to get rid of the nonconvexity of the latter approach we reconstruct as many MR images as the number of coils. To compensate for the ill-posedness of this inverse problem, we leverage structured sparsity of the multi-coil images in a wavelet transform domain while adapting to variations in SNR across coils owing to the OSCAR (octagonal shrinkage and clustering algorithm for regression) regularization. Coil-specific complex-valued MR images are thus obtained by minimizing a convex but nonsmooth objective function using the proximal primal-dual Condat-Vù algorithm. Comparison and validation on retrospective Cartesian and non-Cartesian studies based on the Brain fastMRI data set demonstrate that the proposed reconstruction method outperforms the state-of-the-art (ℓ1-ESPIRiT, calibration-less AC-LORAKS and CaLM methods) significantly on magnitude images for the T1 and FLAIR contrasts. Additionally, further validation operated on 8 to 20-fold prospectively accelerated high-resolution ex vivo human brain MRI data collected at 7 Tesla confirms the retrospective results. Overall, OSCAR-based regularization preserves phase information more accurately (both visually and quantitatively) compared to other approaches, an asset that can only be assessed on real prospective experiments.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="shukla2018multi" class="col-sm-8">
    
      <div class="title">A multi-center study on human brain glutathione conformation using magnetic resonance spectroscopy</div>
      <div class="author">
        
          
            
              
                
                  Shukla Deepika,
                
              
            
          
        
          
            
              
                
                  Mandal Pravat K,
                
              
            
          
        
          
            
              
                
                  Ersland Lars,
                
              
            
          
        
          
            
              
                
                  Grüner Eli Renate,
                
              
            
          
        
          
            
              
                
                  Tripathi Manjari,
                
              
            
          
        
          
            
              
                
                  Raghunathan Partha,
                
              
            
          
        
          
            
              
                
                  Sharma Ankita,
                
              
            
          
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  Punjabi Khushboo,
                
              
            
          
        
          
            
              
                
                  and Splaine Christopher
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://content.iospress.com/download/journal-of-alzheimers-disease/jad180648?id=journal-of-alzheimers-disease%2Fjad180648" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Molecular dynamics simulation and in vitro nuclear magnetic resonance (NMR) studies on glutathione (GSH) indicated existence of closed and extended conformations. The present work in a multi-center research setting reports in-depth analysis of GSH conformers in vivo using a common magnetic resonance spectroscopy (MRS) protocol and signal processing scheme. MEGA-PRESS pulse sequence was applied on healthy subjects using 3T Philips MRI scanner (India) and 3T GE MRI scanner (Norway) using the same experimental parameters (echo time, repetition time, and selective 180° refocusing ON-pulse at 4.40 ppm and 4.56 ppm). All MRS data were processed at one site National Brain Research Center (NBRC) using in-house MRS processing toolbox (KALPANA) for consistency. We have found that both the closed and extended GSH conformations are present in human brain and the relative proportion of individual conformer peak depends on the specific selection of refocusing ON-pulse position in MEGA-PRESS pulse sequence. It is important to emphasize that in vivo experiments with different refocusing and inversion pulse positions, echo time, and voxel size, clearly evidence the presence of both the GSH conformations. The GSH conformer peak positions for the closed GSH (Cys-Hβ) peak at ∼2.80 ppm and extended GSH (Cys-Hβ) peak at ∼2.95 ppm remain consistent irrespective of the selective refocusing OFF-pulse positions. This is the first in vivo study where both extended and closed GSH conformers are detected using the MEGA-PRESS sequence employing the parameters derived from the high resolution in vitro NMR studies on GSH.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="farrens2020pysap" class="col-sm-8">
    
      <div class="title">PySAP: Python Sparse Data Analysis Package for multidisciplinary image processing</div>
      <div class="author">
        
          
            
              
                
                  Farrens S,
                
              
            
          
        
          
            
              
                
                  Grigis A,
                
              
            
          
        
          
            
              
                
                  El Gueddari L,
                
              
            
          
        
          
            
              
                
                  Ramzi Z,
                
              
            
          
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  Starck S,
                
              
            
          
        
          
            
              
                
                  Sarthou B,
                
              
            
          
        
          
            
              
                
                  Cherkaoui H,
                
              
            
          
        
          
            
              
                
                  Ciuciu P,
                
              
            
          
        
          
            
              
                
                  and Starck J-L
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
      
      <a href="http://cosmic.cosmostat.org/wp-content/uploads/2020/07/Farrens_ASCOM2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/CEA-COSMIC/pysap" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">Conference</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="manishkumar2016data" class="col-sm-8">
    
      <div class="title">Data transfer using MCM code</div>
      <div class="author">
        
          
            
              
                
                  Palash Manishkumar Shah,
                
              
            
          
        
          
            
              
                
                  J Agarawal Deepesh,
                
              
            
          
        
          
            
              
                
                  Jiji Tom Ajin,
                
              
            
          
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  and Samhita Varambally
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Multicolored Matrix (MCM) Code is a two-dimensional color coded matrix. It consists a sequence of images rendered at an optimum frame rate to transfer simple data between portable devices such as a mobile phone. We introduce an untried channel-less short range communication technology, designed with limitless storage capacity, great structural stability and flexibility due to which it can work in harsh lighting environments and still combat readability issues in the decoding process. The idea is inspired by the already existing QR code. Our method has various code types in terms of number of colors and size of matrix depending on length of the data. This paper introduces our new idea of data transfer, the technical features of the code along with the encoding-decoding techniques, bit error rates and future scope of improvements for the idea.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="chaithya2021learning" class="col-sm-8">
    
      <div class="title">Learning the sampling density in 2D SPARKLING MRI acquisition for optimized image reconstruction</div>
      <div class="author">
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  Ramzi Zaccharie,
                
              
            
          
        
          
            
              
                
                  and Ciuciu Philippe
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2103.03559" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The SPARKLING algorithm was originally developed for accelerated 2D magnetic resonance imaging (MRI) in the compressed sensing (CS) context. It yields non-Cartesian sampling trajectories that jointly fulfill a target sampling density while each individual trajectory complies with MR hardware constraints. However, the two main limitations of SPARKLING are first that the optimal target sampling density is unknown and thus a user-defined parameter and second that this sampling pattern generation remains disconnected from MR image reconstruction thus from the optimization of image quality. Recently, datadriven learning schemes such as LOUPE have been proposed to learn a discrete sampling pattern, by jointly optimizing the whole pipeline from data acquisition to image reconstruction. In this work, we merge these methods with a state-of-the-art deep neural network for image reconstruction, called XPDNET, to learn the optimal target sampling density. Next, this density is used as input parameter to SPARKLING to obtain 20x accelerated non-Cartesian trajectories. These trajectories are tested on retrospective compressed sensing (CS) studies and show superior performance in terms of image quality with both deep learning (DL) and conventional CS reconstruction schemes.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="gueddari:hal-02399267" class="col-sm-8">
    
      <div class="title">PySAP-MRI: a Python Package for MR Image Reconstruction</div>
      <div class="author">
        
          
            
              
                
                  Gueddari Loubna El,
                
              
            
          
        
          
            
              
                <em><b>Chaithya G R</b></em>,
              
            
          
        
          
            
              
                
                  Ramzi Zaccharie,
                
              
            
          
        
          
            
              
                
                  Farrens Samuel,
                
              
            
          
        
          
            
              
                
                  Starck Sophie,
                
              
            
          
        
          
            
              
                
                  Grigis Antoine,
                
              
            
          
        
          
            
              
                
                  Starck Jean-Luc,
                
              
            
          
        
          
            
              
                
                  and Ciuciu Philippe
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
      
      <a href="https://hal.inria.fr/hal-02399267/file/main_ext.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/CEA-COSMIC/pysap-mri" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">Pre-Prints</h2>
  <ol class="bibliography"></ol>


</div>

  </article>

  
    <div class="social">
      <span class="contact-icon text-center">
  <a href="https://github.com/chaithyagr/chaithyagr.github.io/raw/master/assets/docs/Professional_CV.pdf"><i class="fas fa-user"></i></a>
  <a href="mailto:%63%68%61%69%74%68%79%61%67%72+%67%69%74@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=heX0yHcAAAAJ&hl=en&oi=ao" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  <a href="https://www.researchgate.net/profile/Chaithya_G_R/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
  <a href="https://github.com/chaithyagr" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  <a href="https://www.linkedin.com/in/chaithya-gr-b08aab44" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
  <a href="https://twitter.com/ChaithyaG" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
</span>

      <div class="contact-note"></div>
    </div>
  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Chaithya G. R. .
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha512-/DXTXr6nQodMUiq+IUJYCt2PPOUjrHJ9wFrqpJ3XkgPNOZVfMok7cRw6CSxyCQxXn6ozlESsSh1/sMCTF1rL/g==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"  integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







</html>
